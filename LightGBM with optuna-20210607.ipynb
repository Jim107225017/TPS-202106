{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c295364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun  7 19:27:18 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 462.31       Driver Version: 462.31       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce MX250      WDDM  | 00000000:02:00.0 Off |                  N/A |\n",
      "| N/A   54C    P8    N/A /  N/A |     64MiB /  2048MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check GPU version\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faf9df78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2018 NVIDIA Corporation\n",
      "Built on Sat_Aug_25_21:08:04_Central_Daylight_Time_2018\n",
      "Cuda compilation tools, release 10.0, V10.0.130\n"
     ]
    }
   ],
   "source": [
    "# Check CUDA/cuDNN Version\n",
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41d3218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages\n",
    "!pip install lightgbm\n",
    "!pip install optuna\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997ee356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 即時監控colab資源\n",
    "import wandb\n",
    "\n",
    "# connect with jim107225017/colab/20210526\n",
    "wandb.init(project='colab', entity='jim107225017', name='CPU_GPU', id='20210526')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0093de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install lightgbm GPU in colab\n",
    "# 先登入google cloud\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!pip uninstall lightgbm -y\n",
    "!git clone --recursive https://github.com/Microsoft/LightGBM\n",
    "!cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ba3ec97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 1000, number of used features: 10\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.01 MB) transferred to GPU in 0.001261 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 0.512000\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Optuna\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler   # TPE (Tree-structured Parzen Estimator) sampler\n",
    "from optuna.integration import SkoptSampler   # Scikit-Optimize sampler\n",
    "from optuna.pruners import SuccessiveHalvingPruner   # ASHA : 剪枝演算法，防止over-fitting\n",
    "\n",
    "import lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "\n",
    "from joblib import load, dump\n",
    "\n",
    "def check_gpu_support():\n",
    "    try:\n",
    "        data = np.random.rand(1000, 10)\n",
    "        label = np.random.randint(2, size=1000)\n",
    "        train_data = lightgbm.Dataset(data, label=label)\n",
    "        params = {'device': 'gpu'}\n",
    "        gbm = lightgbm.train(params, train_set=train_data)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "print(check_gpu_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98da66ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # connect with Google Cloud\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# path = \"/content/drive/My Drive/colab/TPS Jun\"\n",
    "path = r'C:\\Users\\Chen\\Desktop\\Kaggle\\Classifier\\Tabular Playground Series - Jun 2021'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eac58004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb77e460",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = []\n",
    "cat_col = [i for i in df_train.columns if i not in ['id', 'target']]\n",
    "target_col = 'target'\n",
    "comb = num_col + cat_col + [target_col]\n",
    "\n",
    "# Label Y\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df_train[target_col])\n",
    "y.astype('int64')\n",
    "y = pd.DataFrame(y, columns=[target_col])\n",
    "\n",
    "x = df_train[cat_col]\n",
    "x_test = df_test[cat_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef3f62d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna\n",
    "PROJECT_NAME = 'lightgbm(optuna)-20210607'\n",
    "SEED = 20210607\n",
    "\n",
    "sampler = TPESampler(seed=SEED)\n",
    "# sampler = SkoptSampler()\n",
    "\n",
    "pruner = SuccessiveHalvingPruner()\n",
    "\n",
    "def objective(trial, kaggle_metrics='LogLoss', predic_proba=True):\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(x, y, test_size=0.2, random_state=SEED, shuffle=True, stratify=y)\n",
    "    \n",
    "    params = {'boosting_type': 'gbdt',\n",
    "              'num_leaves': trial.suggest_int(\"num_leaves\", 10, 200),\n",
    "              'max_depth': trial.suggest_int('max_depth', 1, 25),\n",
    "              'learning_rate': trial.suggest_uniform('learning_rate', 0.01, 1),\n",
    "              'n_estimators': trial.suggest_int(\"n_estimators\", 100, 20000),\n",
    "              'objective': 'multiclass',\n",
    "              'class_weight': None,   # 'balanced': adjust class weight by class size.\n",
    "              'subsample': trial.suggest_uniform('subsample', 0, 1),\n",
    "              'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0, 1),\n",
    "              'reg_alpha': trial.suggest_uniform('reg_alpha', 1e-3, 10),\n",
    "              'reg_lambda': trial.suggest_uniform('reg_lambda', 1e-3, 10),\n",
    "              'random_state': SEED,\n",
    "              'n_jobs': -1,\n",
    "              'device_type': 'gpu',\n",
    "              'metric': 'multi_logloss',\n",
    "              'cat_smooth': trial.suggest_uniform('cat_smooth', 0.1, 100),    \n",
    "             }\n",
    "\n",
    "    clf = LGBMClassifier(**params)\n",
    "    clf.fit(train_x, train_y,\n",
    "            eval_set=[(valid_x, valid_y)],\n",
    "            feature_name=cat_col,\n",
    "            early_stopping_rounds=100,\n",
    "            verbose=False)\n",
    "    \n",
    "    if predic_proba:\n",
    "        preds = clf.predict_proba(valid_x)\n",
    "        preds = np.float64(preds)\n",
    "    else:\n",
    "        preds = clf.predict(valid_x)\n",
    "    \n",
    "    if kaggle_metrics == 'LogLoss':\n",
    "        result = log_loss(valid_y, preds)\n",
    "    elif kaggle_metrics == 'AUC':\n",
    "        result = roc_auc_score(valid_y, preds)\n",
    "    elif kaggle_metrics == 'Acc':\n",
    "        result = accuracy_score(valid_y, preds)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc473c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-07 12:47:44,787]\u001b[0m A new study created in memory with name: lightgbm(optuna)-20210607\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "OPTUNA_OPTIMIZATION = True\n",
    "\n",
    "study = optuna.create_study(direction='minimize', \n",
    "                            sampler=sampler, \n",
    "                            pruner=pruner, \n",
    "                            study_name=PROJECT_NAME,\n",
    "                           )\n",
    "\n",
    "study.optimize(objective, \n",
    "               n_trials=100, \n",
    "               timeout=3*60*60,   # in seconds\n",
    "              )\n",
    "\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial: score {}, params {}'.format(study.best_trial.value, study.best_trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b13ee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create best model\n",
    "# best_params = study.best_trial.params\n",
    "\n",
    "OPTUNA_OPTIMIZATION = True\n",
    "best_params = {}\n",
    "best_params['boosting_type'] = 'gbdt'\n",
    "best_params['num_leaves'] = 47\n",
    "best_params['max_depth'] = 17\n",
    "best_params['learning_rate'] = 0.016006157294323333\n",
    "best_params['n_estimators'] = 4945\n",
    "best_params['objective'] = 'multiclass'\n",
    "best_params['class_weight'] = None\n",
    "best_params['subsample'] = 0.43139189367913644\n",
    "best_params['colsample_bytree'] = 0.1530577924027114\n",
    "best_params['reg_alpha'] = 7.882756575918996\n",
    "best_params['reg_lambda'] = 3.331787587893195\n",
    "best_params['random_state'] = SEED\n",
    "best_params['n_jobs']  = -1\n",
    "best_params['device_type'] = 'gpu'\n",
    "best_params['metric'] = 'multi_logloss'\n",
    "best_params['cat_smooth'] = 16.192565310228396"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef531b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if OPTUNA_OPTIMIZATION:\n",
    "    display(optuna.visualization.plot_optimization_history(study))\n",
    "    display(optuna.visualization.plot_slice(study))\n",
    "    display(optuna.visualization.plot_parallel_coordinate(study))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4097756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if OPTUNA_OPTIMIZATION:\n",
    "    display(study.trials_dataframe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "967ce38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if OPTUNA_OPTIMIZATION:\n",
    "    final_model = LGBMClassifier(**best_params)\n",
    "else:\n",
    "    final_model = LGBMClassifier(**trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf6d2c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Fold 1\n",
      "1.746124621435721\n",
      "--------------------------------------------------\n",
      "Fold 2\n",
      "1.742258148834359\n",
      "--------------------------------------------------\n",
      "Fold 3\n",
      "1.7459103029820238\n",
      "--------------------------------------------------\n",
      "Fold 4\n",
      "1.7460789564366264\n",
      "--------------------------------------------------\n",
      "Fold 5\n",
      "1.7461376297925673\n",
      "--------------------------------------------------\n",
      "Fold 6\n",
      "1.745573683592618\n",
      "--------------------------------------------------\n",
      "Fold 7\n",
      "1.7438839269049153\n",
      "--------------------------------------------------\n",
      "Fold 8\n",
      "1.7447194680475098\n",
      "--------------------------------------------------\n",
      "Fold 9\n",
      "1.7433068769947466\n",
      "--------------------------------------------------\n",
      "Fold 10\n",
      "1.741265495180946\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_preds=None\n",
    "KFOLD = 10\n",
    "\n",
    "kf = StratifiedKFold(n_splits = KFOLD , shuffle = True , random_state = SEED)\n",
    "for fold, (tr_index , val_index) in enumerate(kf.split(x.values , y.values)):\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    \n",
    "    x_train , x_val = x.values[tr_index] , x.values[val_index]\n",
    "    y_train , y_val = y.values[tr_index] , y.values[val_index]\n",
    "        \n",
    "    eval_set = [(x_val, y_val)]\n",
    "    \n",
    "    model = final_model\n",
    "    model.fit(x_train, y_train, eval_set = eval_set, feature_name=cat_col, early_stopping_rounds=100, verbose = False)\n",
    "    dump(model, f'{PROJECT_NAME}_{fold+1}.joblib', compress = 3)\n",
    "    \n",
    "    # train_preds = model.predict(x_train)    \n",
    "    val_preds = model.predict_proba(x_val)\n",
    "    \n",
    "    print(log_loss(y_val, val_preds))\n",
    "    \n",
    "    if test_preds is None:\n",
    "        test_preds = model.predict_proba(x_test.values)\n",
    "    else:\n",
    "        test_preds += model.predict_proba(x_test.values)\n",
    "\n",
    "print(\"-\" * 50)\n",
    "test_preds /= KFOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31e37988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission\n",
    "sub = pd.read_csv('sample_submission.csv')\n",
    "sub[sub.columns[1:]] = test_preds\n",
    "sub.to_csv(f'{PROJECT_NAME}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e340f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
